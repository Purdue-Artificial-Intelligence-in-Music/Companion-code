{"cells":[{"cell_type":"markdown","metadata":{"_uuid":"d3ce7d35c447137adaf6a2b2163fbf54e7b5ab58"},"source":["# **Audio-Score Alignment for Traditional Flute Musical Pieces**\n","## Kernel for alignment of files in Traditional Flute Dataset\n","\n","\n","This kernel serves as an usage example of Traditional Flute Dataset. So, it is recommendable to give it a good look before using the dataset. \n",",\n","Audio to score alignmet is done in two basic steps. First, intermediate representation of audio and score is generated in order to get feature vectors for distance calculation. Second Dynamic Time Warping is used for alignment computation. Results of both steps are displayed graphically as plots.\n","\n","Code starts with some important packages and functions definitions:"]},{"cell_type":"code","execution_count":1,"metadata":{"_uuid":"8c9170a82bac99e65fa1e29793cf78c19d1c140e","collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'librosa'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[1;32mIn[1], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# import matplotlib.pyplot as plt\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# import librosa as lr\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mload\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mld\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnote_filter\u001b[39m(f0_array, fmin\u001b[38;5;241m=\u001b[39mlr\u001b[38;5;241m.\u001b[39mnote_to_midi(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mB3\u001b[39m\u001b[38;5;124m'\u001b[39m), fmax\u001b[38;5;241m=\u001b[39mlr\u001b[38;5;241m.\u001b[39mnote_to_midi(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mB9\u001b[39m\u001b[38;5;124m'\u001b[39m), fs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m44100\u001b[39m, resolution_octave\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, harmonics\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, beta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m):\n\u001b[0;32m     11\u001b[0m     faux \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinspace(fmin, fmax, (fmax\u001b[38;5;241m-\u001b[39mfmin)\u001b[38;5;241m*\u001b[39mresolution_octave)\n","File \u001b[1;32mc:\\Users\\Nick\\github\\Nick-Ko-Companion-code\\traditional-flute-dataset\\load.py:9\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#!/usr/bin/env python2\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# -*- coding: utf-8 -*-\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03mCreated on Sun Apr  9 19:20:29 2017\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \n\u001b[0;32m      6\u001b[0m \u001b[38;5;124;03m@author: jbraga\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlibrosa\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mlr\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwavfile\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mwav\u001b[39;00m\n","\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'librosa'"]}],"source":["import sys\n","sys.path.append('../input/traditional-flute-dataset/')\n","# import fastdtw \n","# import IPython.display\n","import numpy as np\n","# import matplotlib.pyplot as plt\n","# import librosa as lr\n","import load as ld\n","\n","def note_filter(f0_array, fmin=lr.note_to_midi('B3'), fmax=lr.note_to_midi('B9'), fs=44100, resolution_octave=1, harmonics=0, beta=0.1):\n","    faux = np.linspace(fmin, fmax, (fmax-fmin)*resolution_octave)\n","    filter_aux = np.zeros((len(faux), len(f0_array)))\n","    for j in range(0, len(f0_array)):\n","        if f0_array[j] == 0:\n","            filter_aux[:,j] = beta*np.ones(len(faux))\n","        else:\n","            idx=resolution_octave*int(f0_array[j]-fmin)\n","            filter_aux[idx, j] = 1\n","            if harmonics > 0: \n","                if (idx+12*resolution_octave) < len(faux): #octava\n","                    filter_aux[idx+12*resolution_octave, j] = 1\n","                if harmonics > 1:    \n","                    if (idx+19*resolution_octave) < len(faux): #octava + quinta\n","                        filter_aux[idx+19*resolution_octave, j] = 1\n","                        if harmonics > 2:    \n","                            if (idx+24*resolution_octave) < len(faux): #octava + quinta\n","                                filter_aux[idx+24*resolution_octave, j] = 1            \n","                            if harmonics > 3:    \n","                                if (idx+28*resolution_octave) < len(faux): #octava + quinta\n","                                    filter_aux[idx+28*resolution_octave, j] = 1\n","                                if harmonics > 4:    \n","                                    if (idx+31*resolution_octave) < len(faux): #octava + quinta\n","                                        filter_aux[idx+31*resolution_octave, j] = 1 \n","                                    if harmonics > 5:    \n","                                        if (idx+34*resolution_octave) < len(faux): #octava + quinta\n","                                            filter_aux[idx+31*resolution_octave, j] = 1   \n","\n","    return filter_aux"]},{"cell_type":"markdown","metadata":{"_uuid":"ed365d34f80a371c25fad4ad84575cf794b4ac1e"},"source":["## Dataset file loading\n","Audio, score and ground truth are loaded from de dataset (if you are willing to use it please give a detailed look!). Also params for intermediate representation are defined. "]},{"cell_type":"code","execution_count":7,"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[],"source":["if __name__==\"__main__\":\n","   \n","    #distance function param\n","    distancefun_param = ['cosine', 'euclidean']\n","    distancefun = distancefun_param[0]\n","    print('distance: ' + distancefun)\n","    \n","    #bins params\n","    bins_param = [12, 24, 36]\n","    bins = bins_param[1]\n","    print('bins per octave: ' + str(bins))\n","    \n","    #range param: flute register\n","    end_note = lr.note_to_midi('B9')\n","    range_bins = lr.note_to_midi('B9') - lr.note_to_midi('B3')\n","    \n","    #harmonics param\n","    harmonics_param = [0, 1, 2, 3, 4, 5, 6]\n","    harmonics = harmonics_param[1]\n","    print('harmonics in score codification: ' + str(harmonics))\n"," \n","    #windows params\n","    hop_param = [128, 256, 512, 1024, 2048, 4096]\n","    hop = hop_param[1]\n","    print('hop size: ' + str(hop))\n","\n","    #fragment params\n","    fragments = ld.list_of_fragments('../input/traditional-flute-dataset/dataset.csv')\n","    fragment = fragments[10]\n","    print('fragment: ' + fragment)    \n","\n","    #load files: audio, gt, score\n","    audio_file = '../input/traditional-flute-dataset/audio/' + fragment + '.wav'\n","    audio, t, fs = ld.audio(audio_file)\n","\n","    gt_file = '../input/traditional-flute-dataset/ground_truth/' + fragment + '.gt'\n","    gt_onset, gt_note, gt_duration = ld.ground_truth(gt_file)\n","    gt_note=lr.hz_to_midi(gt_note)\n","    gt_note[np.isinf(gt_note)]=0   \n","    gt_array, gt_t, gt_index = ld.to_array(gt_onset, gt_note, gt_duration, fs, hop)\n","\n","    score_file = '../input/traditional-flute-dataset/score/' + fragment[0:fragment.rfind('_')] + '.notes'\n","    score_onset, score_note, score_duration = ld.score(score_file)\n","    score_array, score_t, score_index = ld.to_array(score_onset, score_note, score_duration, fs, hop)"]},{"cell_type":"markdown","metadata":{"_uuid":"fce9fa4b802b9f74026ffed6820fdcb7281ea72b"},"source":["## Intermediate representation generation for audio and score\n","After computing the intermediate representation they are both plotted for visualization:"]},{"cell_type":"code","execution_count":10,"metadata":{"_uuid":"7e4c9d1cae7d5d1178fc7e8605baf65e1c4d6a38","collapsed":true,"jupyter":{"outputs_hidden":true},"scrolled":true,"trusted":true},"outputs":[],"source":["    #generate intermediate representation with score\n","    note_fb = note_filter(score_array, resolution_octave=int(bins/12), harmonics=harmonics)         \n","\n","    C = lr.core.cqt(audio, sr=fs, hop_length=hop, fmin=lr.note_to_hz('B3'),\n","                    n_bins=range_bins*int(bins/12),bins_per_octave=bins,tuning=None, \n","                    filter_scale=1,sparsity=0.3, norm=1, scale=True)\n","\n","    Cxx = np.abs(C) + 0.001      \n","    \n","    plt.figure(figsize=(10,5))\n","    plt.subplot(1,2,1)\n","    plt.pcolormesh(note_fb)\n","    plt.subplot(1,2,2)\n","    plt.pcolormesh(np.log10(Cxx))"]},{"cell_type":"markdown","metadata":{"_uuid":"975a630f716668c4eab63e4a36dddaadddd36b17"},"source":["## Temporal series alignment with DTW\n","This piece of code takes computed intermediate representations and generate the best alignment path. Results are plotted for visualization:"]},{"cell_type":"code","execution_count":17,"metadata":{"_uuid":"1ebc84a3f4012d5cdd937056d5e9ad43c147d146","collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"source":["    #%% DTW\n","    from scipy.spatial.distance import cosine \n","    from scipy.spatial.distance import euclidean\n","    if distancefun == 'cosine':\n","        distance, path= fastdtw.fastdtw(Cxx.T[:(len(gt_array)-Cxx.shape[1]),:], note_fb.T, dist=cosine)\n","    elif distancefun == 'euclidean':\n","        distance, path= fastdtw.fastdtw(Cxx.T[:(len(gt_array)-Cxx.shape[1]),:], note_fb.T, dist=euclidean)\n","    path = np.array(path)\n","\n","#%%  ALIGNMENT PLOTTING\n","    fig = plt.figure(figsize=(18,6))                                                               \n","    ax = fig.add_subplot(3,1,(1,2))                                             \n","    yticks_major = [ 59, 60, 62, 64, 65, 67, 69, 71, 72, 74, 76, 77, 79, 81, 83, 84, 86, 88, 89, 91, 93, 95, 96, 98, 100 ]\n","    yticks_minor = [ 61, 63, 66, 68, 70, 73, 75, 78, 80, 82, 85, 87, 90, 92, 94, 97, 99 ]\n","    yticks_labels = ['59-B3', '60-C4', '62-D4', '64-E4', '65-F4', '67-G4', '69-A4', '71-B4', '72-C5', '74-D5', '76-E5', '77-F5', '79-G5', '81-A5', '83-B5', '84-C6', '86-D6', '88-E6', '89-F6', '91-G6', '93-A6', '95-B6', '96-C7', '98-D7', '100-E7']                         \n","    ax.set_yticks(yticks_major)                                                   \n","    ax.set_yticks(yticks_minor, minor=True)\n","    ax.set_yticklabels(yticks_labels, size='small')                                \n","    ax.set_ylim([58, 101]) #flute register in midi   \n","    ax.set_xlim([0, gt_t[-1]])\n","    ax.grid(b=True, which='major', color='black', axis='y', linestyle='-', alpha=0.3)\n","    ax.grid(b=True, which='minor', color='black', axis='y', linestyle='-', alpha=1)    \n","    plt.plot(gt_t, gt_array, color='red', lw=0.8)\n","    plt.plot(gt_t[path[:,0]], score_array[path[:,1]], color='blue', lw=0.8)\n","    plt.fill_between(gt_t, gt_array-0.5, gt_array+0.5, facecolor='magenta', label='gt', alpha=0.6)\n","    plt.fill_between(gt_t[path[:,0]], score_array[path[:,1]]-0.5, score_array[path[:,1]]+0.5, facecolor='cyan', label='aligned score', alpha=0.6)\n","    plt.legend()\n","    plt.title(\"Alignment plot\")\n","    plt.ylabel(\"Notes (American Notation)\")\n","    plt.subplot(3,1,3)\n","    plt.plot(t, audio, color='black', alpha=0.5)\n","    plt.grid()\n","    plt.axis('tight')\n","    plt.ylabel(\"Amplitude\")\n","    plt.xlabel(\"Time (s)\")    \n","    plt.xlim([gt_t[0], gt_t[-1:]])\n","    plt.show()"]},{"cell_type":"markdown","metadata":{"_uuid":"df08a031d16bf8d1d9af26a7b51decbfe94bc759"},"source":["## Final comments\n","With this kernel you should be able to manipulate and play with Traditional Flute Dataset. Please feel free to contact me for further questions or comments."]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"b79ccbc9581322f1ebe310e25f829635e18c0cc9","collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"source":[]}],"metadata":{"anaconda-cloud":{},"kaggle":{"accelerator":"none","dataSources":[{"datasetId":27138,"sourceId":34890,"sourceType":"datasetVersion"}],"dockerImageVersionId":2854,"isGpuEnabled":false,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"}},"nbformat":4,"nbformat_minor":4}
